{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RMR1k-1AlUQD"
   },
   "outputs": [],
   "source": [
    "!pip install stanza\n",
    "import stanza\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2eMeQ-hlWaL"
   },
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"proyectoPura.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT Título_Obra FROM OBRAS\n",
    "UNION ALL\n",
    "SELECT Título_Complemento FROM COMPLEMENTOS\n",
    "UNION ALL\n",
    "SELECT Título_Sección FROM SECCIONES_PUBLICADAS\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query)\n",
    "titles = cur.fetchall()\n",
    "#print(titles)\n",
    "\n",
    "titles_list = []\n",
    "for title in titles:\n",
    "  if title[0] is not None:\n",
    "    titles_list.append(title[0])\n",
    "  if title[0] is None:\n",
    "    titles_list.append(\"NULL\") #we take into account \"NULL\" titles, to keep the same structure as original DB.\n",
    "print(titles_list)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYc-2BqjlWX5"
   },
   "outputs": [],
   "source": [
    "#Delimitation of titles (later recognizing them)\n",
    "import re\n",
    "def find_delimit_subtit(text):\n",
    "  subtitle_ = re.sub(r'\\s*\"\\s*-\\s*|\\s*-\\s*\"\\s*|\\s*-\\s*\"\\s*-\\s*|\\s*\\[\\.\\.\\.\\]\\s*\"\\s*-\\s*', r' | ', text)\n",
    "  return subtitle_\n",
    "\n",
    "encontrar_subtit = [find_delimit_subtit(row) for row in titles_list]\n",
    "list_titsub = [row for row in encontrar_subtit if \" | \" in row]\n",
    "\n",
    "#only this exceptions do not adjust to pattern (2 rows):\n",
    "excepcion_1 = \"\"\"Piquer-Oda \"Alzad vuestras\"\"\"\n",
    "excepcion_2 = \"\"\"Matrimonios por anuncios-Los baños de Biarritz\"\"\"\n",
    "for i, row in enumerate(encontrar_subtit):\n",
    "  if excepcion_1 in row:\n",
    "    encontrar_subtit[i] = row.replace('\"', '| ')\n",
    "  if excepcion_2 in row:\n",
    "    encontrar_subtit[i]= row.replace('-', ' | ')\n",
    "\n",
    "print(encontrar_subtit[249])\n",
    "print(encontrar_subtit[207])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WI-ET6hSlWVb"
   },
   "outputs": [],
   "source": [
    "#we continue preparing each title to process it through model (tok,lemm,pos,depparse,ner)\n",
    "import re\n",
    "\n",
    "def clean_per_title(title):\n",
    "  cleaned_text = re.sub(\n",
    "    r'\\s*\\(\\s*(Continuación|Fragmentos?|Conclusión|Conclusiones?|Conclusion)\\.?\\s*\\)\\s*',\n",
    "    ' ',\n",
    "    title)\n",
    "  cleaned_text = re.sub(r'\\s*\"\\s*|\\s*\\[\\s*\\.\\s*\\.\\s*\\.\\s*\\]\\s*|\\s*\\[\\s*\\u2026\\s*\\]\\s*', ' ', cleaned_text)\n",
    "  return cleaned_text.strip()\n",
    "\n",
    "cleaned_rows = [clean_per_title(row) for row in encontrar_subtit]\n",
    "\n",
    "#print(cleaned_rows)\n",
    "\n",
    "for row in cleaned_rows:\n",
    "  if \" | \" in row:\n",
    "    cleaned_rows[i] = row.split(\" | \")\n",
    "\n",
    "#for row in cleaned_rows:\n",
    "  #print(row, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YyvhTv2IlWTB"
   },
   "outputs": [],
   "source": [
    "#we start building up the function to process each title and each subtitle\n",
    "# START HERE TOMORROW, NOT ENDED 18.03.2025.\n",
    "def processing_1(text, nlp_model):\n",
    "  doc = nlp_model(text)\n",
    "  if text != \"NULL\":\n",
    "    return [(word.text, word.lemma, word.upos, word.head, word.deprel) for sent in doc.sentences for word in sent.words]\n",
    "  else:\n",
    "    return [(\"NULL\")]\n",
    "nlp_es = stanza.Pipeline(lang=\"es\", processors=\"tokenize,mwt,pos,lemma,ner,depparse\")\n",
    "\n",
    "processed_titles_es = [processing_1(row, nlp_es) for row in titles_list]\n",
    "\n",
    "processed_titles_es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbRJ_pKjlWQW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wkoUbiilWN0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StFeCGqWlWK9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sbdz5j8JlWHg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gwf-5imlWDi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aooa-DTUlV8T"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
=======
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMR1k-1AlUQD"
      },
      "outputs": [],
      "source": [
        "!pip install stanza\n",
        "import stanza\n",
        "import sqlite3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2eMeQ-hlWaL"
      },
      "outputs": [],
      "source": [
        "con = sqlite3.connect(\"proyectoPura.db\")\n",
        "cur = con.cursor()\n",
        "\n",
        "query = \"\"\"\n",
        "SELECT Título_Obra FROM OBRAS\n",
        "UNION ALL\n",
        "SELECT Título_Complemento FROM COMPLEMENTOS\n",
        "UNION ALL\n",
        "SELECT Título_Sección FROM SECCIONES_PUBLICADAS\n",
        "\"\"\"\n",
        "\n",
        "cur.execute(query)\n",
        "titles = cur.fetchall()\n",
        "#print(titles)\n",
        "\n",
        "titles_list = []\n",
        "for title in titles:\n",
        "  if title[0] is not None:\n",
        "    titles_list.append(title[0])\n",
        "  if title[0] is None:\n",
        "    titles_list.append(\"NULL\") #we take into account \"NULL\" titles, to keep the same structure as original DB.\n",
        "print(titles_list)\n",
        "\n",
        "con.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYc-2BqjlWX5"
      },
      "outputs": [],
      "source": [
        "#Delimitation of titles (later recognizing them)\n",
        "import re\n",
        "def find_delimit_subtit(text):\n",
        "  subtitle_ = re.sub(r'\\s*\"\\s*-\\s*|\\s*-\\s*\"\\s*|\\s*-\\s*\"\\s*-\\s*|\\s*\\[\\.\\.\\.\\]\\s*\"\\s*-\\s*', r' | ', text)\n",
        "  return subtitle_\n",
        "\n",
        "encontrar_subtit = [find_delimit_subtit(row) for row in titles_list]\n",
        "list_titsub = [row for row in encontrar_subtit if \" | \" in row]\n",
        "\n",
        "#only this exceptions do not adjust to pattern (2 rows):\n",
        "excepcion_1 = \"\"\"Piquer-Oda \"Alzad vuestras\"\"\"\n",
        "excepcion_2 = \"\"\"Matrimonios por anuncios-Los baños de Biarritz\"\"\"\n",
        "for i, row in enumerate(encontrar_subtit):\n",
        "  if excepcion_1 in row:\n",
        "    encontrar_subtit[i] = row.replace('\"', '| ')\n",
        "  if excepcion_2 in row:\n",
        "    encontrar_subtit[i]= row.replace('-', ' | ')\n",
        "\n",
        "print(encontrar_subtit[249])\n",
        "print(encontrar_subtit[207])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI-ET6hSlWVb"
      },
      "outputs": [],
      "source": [
        "#we continue preparing each title to process it through model (tok,lemm,pos,depparse,ner)\n",
        "import re\n",
        "\n",
        "def clean_per_title(title):\n",
        "  cleaned_text = re.sub(\n",
        "    r'\\s*\\(\\s*(Continuación|Fragmentos?|Conclusión|Conclusiones?|Conclusion)\\.?\\s*\\)\\s*',\n",
        "    ' ',\n",
        "    title)\n",
        "  cleaned_text = re.sub(r'\\s*\"\\s*|\\s*\\[\\s*\\.\\s*\\.\\s*\\.\\s*\\]\\s*|\\s*\\[\\s*\\u2026\\s*\\]\\s*', ' ', cleaned_text)\n",
        "  return cleaned_text.strip()\n",
        "\n",
        "cleaned_rows = [clean_per_title(row) for row in encontrar_subtit]\n",
        "\n",
        "#print(cleaned_rows)\n",
        "\n",
        "cleaned_rows = [row.split(\" | \") if \" | \" in row else row for row in cleaned_rows]\n",
        "\n",
        "for row in cleaned_rows:\n",
        "  print(row, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyvhTv2IlWTB"
      },
      "outputs": [],
      "source": [
        "#we start building up the function to process each title and each subtitle\n",
        "# START HERE TOMORROW, NOT ENDED 18.03.2025.\n",
        "def processing_1(text, nlp_model):\n",
        "  doc = nlp_model(text)\n",
        "  if text != \"NULL\":\n",
        "    return [(word.text, word.lemma, word.upos, word.head, word.deprel) for sent in doc.sentences for word in sent.words]\n",
        "  else:\n",
        "    return [(\"NULL\")]\n",
        "nlp_es = stanza.Pipeline(lang=\"es\", processors=\"tokenize,mwt,pos,lemma,ner,depparse\")\n",
        "\n",
        "processed_titles_es = [processing_1(row, nlp_es) for row in titles_list]\n",
        "\n",
        "processed_titles_es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbRJ_pKjlWQW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wkoUbiilWN0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StFeCGqWlWK9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sbdz5j8JlWHg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gwf-5imlWDi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aooa-DTUlV8T"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
>>>>>>> eae431a3889227140d6477186078d320e28530d4
}
